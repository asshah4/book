[
["index.html", "Thoughts Preface", " Thoughts Anish Shah 2020-06-12 Preface This initially was designed to help document exploratory concepts that were developed using the card package, but also expanded to clinical concepts leveraging the power of R and Rmarkdown. As this develops, it will likely create its own order. Currently it revolves around the principal components: circadian rhythm electrocardiography autonomic physiology clinical medicine programming "],
["intro.html", "Chapter 1 Introduction", " Chapter 1 Introduction An introduction would go here. "],
["r-and-rstudio.html", "1.1 R and RStudio", " 1.1 R and RStudio I have been learning R since 2010, and have found it to be an excellent: open-source excellent community an outstanding IDE with RStudio package development Currently using R version 4.0.0 (2020-04-24), nicknamed Arbor Day, with RStudio 1.3. "],
["git-and-github.html", "1.2 git and Github", " 1.2 git and Github "],
["technical.html", "Chapter 2 Technical ", " Chapter 2 Technical "],
["building-a-cv.html", "2.1 Building a CV", " 2.1 Building a CV "],
["troubleshooting-git.html", "2.2 Troubleshooting Git", " 2.2 Troubleshooting Git "],
["circadian.html", "Chapter 3 Circadian Physiology ", " Chapter 3 Circadian Physiology "],
["chronobiology.html", "3.1 Chronobiology", " 3.1 Chronobiology Will discuss circadian biology/physiology. "],
["circadian-disruption.html", "3.2 Circadian Disruption", " 3.2 Circadian Disruption "],
["references.html", "3.3 References", " 3.3 References "],
["cosinor.html", "Chapter 4 Cosinor Analysis", " Chapter 4 Cosinor Analysis The issue with time series analysis is that the data is by its nature circular and thus cannot be easily be analyzed through traditional, linear methods. The following is the development/expansion of the cosinor model to help study circadian rhythms (3) using R. "],
["overview.html", "4.1 Overview", " 4.1 Overview The card package was developed to help tackle this problem. # Library library(card) library(tidyverse) ## ── Attaching packages ──────────────────── tidyverse 1.3.0 ── ## ✓ ggplot2 3.3.1 ✓ purrr 0.3.4 ## ✓ tibble 3.0.1 ✓ dplyr 1.0.0 ## ✓ tidyr 1.1.0 ✓ stringr 1.4.0 ## ✓ readr 1.3.1 ✓ forcats 0.5.0 ## ── Conflicts ─────────────────────── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() # Dataset data(&quot;twins&quot;) # Example of data ggplot(twins, aes(x = hour, y = rDYX)) + geom_smooth(method = &quot;gam&quot;, se = TRUE) ## `geom_smooth()` using formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; Using the cosinor() function, the characteristics of the circadian pattern can be retrieved. # Cosinor model m &lt;- cosinor(rDYX ~ hour, twins, tau = 24) summary(m) ## Individual Cosinor Model ## ------------------------------------------ ## Call: ## cosinor(&quot;rDYX ~ hour&quot;) ## ## Residuals: ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -3.12633 -0.53228 -0.03597 0.00000 0.49132 4.82150 ## ## Coefficients: ## mesor amp phi beta gamma ## 2.8604855 0.2986101 -2.6687044 -0.2658396 0.1360048 ## ## Confidence Intervals: ## 2.5% 97.5% ## mesor 2.8485315 2.8724394 ## amp 0.2814656 0.3157546 ## phi -2.7252732 -2.6121357 The statistical principles behind this method allow for different methods to model, diagnose, and interpret findings. (Refinetti, Cornélissen, and Halberg 2007; Cornelissen 2014) single component cosinor multiple component cosinor population cosinor confidence intervals (ellipse method) zero amplitude test lack-of-fit testing The example here use the dataset twins which contains a continuous ECG signal, called DYX, collected at hourly time points. References "],
["single-component-cosinor.html", "4.2 Single component cosinor", " 4.2 Single component cosinor The single component cosinor method is modeled as: \\[Y(t) = M + A cos(\\frac{2 \\pi t}{\\tau} + \\phi) + \\epsilon\\] Where: \\[ \\begin{aligned} M &amp;= MESOR\\ (midline\\ estimating\\ statistic\\ of\\ rhythm) \\\\ t &amp;= time in hours \\\\ \\epsilon &amp;= error \\\\ \\phi &amp;= acrophase \\\\ \\tau &amp;= tau\\ (period) \\\\ \\end{aligned} \\] To model this function, it must be transformed linearly to assess the coefficients. \\[Y(t) = M + \\beta x_{t} + \\gamma z_{t} + \\epsilon_{t}\\] The new coefficients and parameters are defined as: \\[ \\begin{aligned} \\beta &amp;= A cos(\\phi) \\\\ \\gamma &amp;= -A sin(\\phi) \\\\ x_{t} &amp;= cos(\\frac{2 \\pi t}{\\tau}) \\\\ z_{t} &amp;= sin(\\frac{2 \\pi t}{\\tau}) \\\\ \\end{aligned} \\] In the twins data, the time value \\(t\\) is measured in hours. As this is 24-hour data, the assumption is that \\(\\tau = 24\\). df &lt;- subset(twins, patid == 60) # Single individual cosinor y &lt;- df$rDYX t &lt;- df$hour n &lt;- length(t) # Number of observations period &lt;- 24 # Transformed variables x &lt;- cos(( 2 * pi * t) / period) z &lt;- sin(( 2 * pi * t) / period) To generate the coefficients in R requires sovling a matrix of normal/linear equations. # Matrices ymat &lt;- as.matrix(cbind(y = c(sum(y), sum(y * x), sum(y * z)))) mcol &lt;- c(n, sum(x), sum(z)) # Mesor column bcol &lt;- c(sum(x), sum(x^2), sum(x * z)) # Beta column gcol &lt;- c(sum(z), sum(x * z), sum(z^2)) # Gamma column xmat &lt;- as.matrix(cbind(m = mcol, b = bcol, g = gcol)) # Solution coefs &lt;- solve(t(xmat) %*% xmat, tol = 1e-21) %*% (t(xmat) %*% ymat) mesor &lt;- coefs[1] # mesor beta &lt;- coefs[2] # beta gamma &lt;- coefs[3] # gamma For a single cosinor, as in, the analysis of the values from a single individual over 1 period, the values for the Amplitude (\\(A\\)) and Acrophase (\\(\\phi\\)) can be calculated. \\[ \\begin{aligned} A &amp;= \\sqrt{(\\beta^2 + \\gamma^2)} \\phi &amp;= k \\pi + g \\times arctan(\\frac{\\gamma}{\\beta}) \\end{aligned} \\] Because the values of \\(\\gamma\\) and \\(\\beta\\) represent trigonemtric values, the position or quadrant of the circle changes the value of \\(\\phi\\). \\(\\beta\\) \\(\\gamma\\) k g + + 0 -1 + - \\(-2 \\pi\\) +1 - + \\(- \\pi\\) +1 - - \\(- \\pi\\)$ -1 These calculations were made with the cosinor model seen above. # Amplitude amp &lt;- sqrt(beta^2 + gamma^2) # Acrophase (phi) must be in correct quadrant sb &lt;- sign(beta) sg &lt;- sign(gamma) theta &lt;- atan(abs(gamma / beta)) if ((sb == 1 | sb == 0) &amp; sg == 1) { phi &lt;- -theta } else if (sb == -1 &amp; (sg == 1 | sg == 0)) { phi &lt;- theta - pi } else if ((sb == -1 | sb == 0) &amp; sg == -1) { phi &lt;- -theta - pi } else if (sb == 1 &amp; (sg == -1 | sg == 0)) { phi &lt;- theta - (2 * pi) } cat(paste0(&quot;Amplitude = &quot;, round(amp, 3))) ## Amplitude = 0.168 cat(paste0(&quot;Acrophase = &quot;, round(phi, 3))) ## Acrophase = -2.676 "],
["population-mean-cosinor.html", "4.3 Population-mean cosinor", " 4.3 Population-mean cosinor Based on the work by Cornelissen et al 2014 (Cornelissen 2014), the population mean cosinor can be estimated by applying the single or multiple component cosinor to each individual. \\[\\{\\hat{u} = \\hat{M}_{i} + \\hat\\beta_{i} + \\hat\\gamma_{i} + ... \\}\\] Where \\(i = 1, 2, ..., k\\) for each individual contribution to the population cosinor metrics. Each parameter can then be “averaged” to estimate the population parameters. This allows extension from a single individual to populations, particularly research studies with cohorts of patients. The \\(A\\) and \\(\\phi\\) however are calculated using the previous equations but through the \\(\\mu_{\\beta}\\) and \\(\\mu_{\\gamma}\\) values. The MESOR can be calculated simply by measure the mean value from each sample (\\(MESOR_{population} = MESOR_{1} + ... + MESOR_{k}\\)). # Parameters for population mean cosinor, using best datasets df &lt;- twins %&gt;% filter(med_beta_blockers != 1) %&gt;% select(c(&quot;rDYX&quot;, &quot;hour&quot;, &quot;patid&quot;)) names(df) &lt;- c(&quot;y&quot;, &quot;t&quot;, &quot;pop&quot;) highCounts &lt;- df %&gt;% group_by(pop) %&gt;% tally() %&gt;% filter(n &gt; 20) # Subset for full data df &lt;- subset(df, pop %in% highCounts$pop) # Number of individuals k &lt;- length(unique(df$pop)) # Individual cosinor models are implemented for each individual kCosinors &lt;- with( df, by(df, pop, function(x) { cosinor(y ~ t, data = x, tau = 24) }) ) # The coefficients have to be extracted and summarized tbl &lt;- sapply(kCosinors, stats::coef) coef_names &lt;- c(&quot;mesor&quot;, &quot;amp&quot;, &quot;phi&quot;, &quot;beta&quot;, &quot;gamma&quot;) rownames(tbl) &lt;- coef_names xmat &lt;- t(tbl) # Get mean for each parameter (mesor, beta, gamma), ignoring averaged amp/phi coefs &lt;- apply(xmat, MARGIN = 2, function(x) { sum(x) / k }) mesor &lt;- unname(coefs[&quot;mesor&quot;]) beta &lt;- unname(coefs[&quot;beta&quot;]) gamma &lt;- unname(coefs[&quot;gamma&quot;]) # Get amplitude amp &lt;- sqrt(beta^2 + gamma^2) # Acrophase (phi) must be in correct quadrant sb &lt;- sign(beta) sg &lt;- sign(gamma) theta &lt;- atan(abs(gamma / beta)) if ((sb == 1 | sb == 0) &amp; sg == 1) { phi &lt;- -theta } else if (sb == -1 &amp; (sg == 1 | sg == 0)) { phi &lt;- theta - pi } else if ((sb == -1 | sb == 0) &amp; sg == -1) { phi &lt;- -theta - pi } else if (sb == 1 &amp; (sg == -1 | sg == 0)) { phi &lt;- theta - (2 * pi) } # Update coefficients coefs[&quot;amp&quot;] &lt;- amp coefs[&quot;phi&quot;] &lt;- phi # Updated coefficients names(coefs) &lt;- coef_names print(coefs) ## mesor amp phi beta gamma ## 2.9020896 0.3144840 -2.6948505 -0.2836203 0.1358664 4.3.1 Confidence Intervals for Population Cosinor The confidence intervals for a population are more complicated to generate, and several approaches are documented in the literature. 4.3.1.1 Ellipsoid Approach The values, including standard deviation and standard error for the MESOR are calculated using standard statistics along a t-distribution, with degree of freedom based on number of observations. In this case, \\(\\alpha = 0.05\\). # Standard error for mesor kcoefs &lt;- data.frame(xmat) se &lt;- sd(kcoefs$mesor) / sqrt(k - 1) cat(round(se, 3)) ## 0.022 The statistical parameters around the \\(A\\) and \\(\\phi\\) are more complex, as they are joined together, and represent a joint confidence region of the substitute parameters \\(\\beta\\) and \\(\\gamma\\). The first step is the calculation of the variance and covariance of \\(\\beta\\) and \\(\\gamma\\). This can be used to generated teh standard deviation of these variables. \\[ \\begin{aligned} \\sigma_{\\beta \\gamma} &amp;= \\sqrt{COV_{\\beta \\gamma}} \\\\ \\sigma_{\\beta} &amp;= \\sqrt{VAR_{\\beta}} \\\\ \\sigma_{\\gamma} &amp;= \\sqrt{VAR_{\\gamma}} \\\\ \\end{aligned} \\] sbg &lt;- sqrt(cov(kcoefs$beta, kcoefs$gamma)) sb &lt;- sqrt(var(kcoefs$beta)) sg &lt;- sqrt(var(kcoefs$gamma)) The next step is the creation of a confidence ellipse for a given confidence interval. This ellipse is defined by all points \\((\\beta*, \\gamma*)\\) that satisfy the elliptical equation. \\[ \\frac{(\\beta - \\beta*)^2}{\\sigma^2_{\\beta}} - \\frac{2r(\\beta - \\beta*)(\\gamma - \\gamma*)}{\\sigma_{\\beta} \\sigma_{\\gamma}} + \\frac{(\\gamma - \\gamma*)}{\\sigma^2_{\\gamma}} = \\frac{2(1 - r^2)(k - 1)F_{1 - \\alpha}}{k(k - 2)} \\] This can be reorganized/reorderd by solving for a single parameter first, such as \\(\\beta*\\), which will lead to two potential values. \\[ \\beta* = \\frac{ \\beta \\sigma_{\\gamma} - r \\sigma_{beta} \\gamma + r \\sigma_{beta} \\gamma* \\pm \\sqrt{(r^2 - 1)[(\\gamma* - \\gamma)^2 - \\frac{2(k-1)}{k(k-2)}F_{1-\\alpha}\\sigma^2_{\\gamma}]} } {\\sigma_{\\gamma}} \\] … where \\(r = \\frac{\\sigma_{\\beta \\gamma}}{\\sigma_{\\beta} \\sigma_{\\gamma}}\\) This is calculated using the above equation for a potential sequence of values of \\(\\beta*\\) and \\(\\gamma*\\). THe constant values are already known to us, including the \\(\\beta\\) and \\(\\gamma\\) variables. # Variance/covariance and initial values were found above # Define new constants alpha &lt;- 0.05 r &lt;- sbg / (sb * sg) fstat &lt;- qf(1 - alpha, 2, k - 2) # Sequence values gseq &lt;- seq(from = -abs(gamma*3), to = abs(gamma*3), length.out = 100) bpos &lt;- ((beta * sg) - (r * sb * gamma) + (r * sb * gseq) + (sb * sqrt(as.complex((r^2 - 1) * ((gseq - gamma)^2 - ((2 * (k - 1)) / (k * (k - 2)) * fstat * sg^2)))))) / sg bneg &lt;- ((beta * sg) - (r * sb * gamma) + (r * sb * gseq) - (sb * sqrt(as.complex((r^2 - 1) * ((gseq - gamma)^2 - ((2 * (k - 1)) / (k * (k - 2)) * fstat * sg^2)))))) / sg # Restrict to only real numbers (not complex/imaginary) index &lt;- Im(bpos) == 0 | Im(bpos) == Im(bneg) # values are zero in both are REAL numbers gseq &lt;- Re(gseq[index]) bpos &lt;- Re(bpos[index]) bneg &lt;- Re(bneg[index]) # Plot out ellipse ggplot() + # Original values geom_point(aes(x = gamma, y = beta), data = kcoefs, alpha = 0.2) + # Potential ellipse versus hyperbola geom_point(aes(x = gseq, y = bpos), col = &quot;red&quot;, size = 0.5) + geom_point(aes(x = gseq, y = bneg), col = &quot;blue&quot;, size = 0.5) + # Predicted segment geom_segment(aes(x = 0, y = 0, xend = -amp*sin(phi), yend = amp*cos(phi)), size = 1.5) + # Axes geom_vline(xintercept = 0) + geom_hline(yintercept = 0) + xlim(-abs(gamma)*5, abs(gamma)*5) + ylim(-abs(beta)*5, abs(beta)*5) ## Warning: Removed 7 rows containing missing values (geom_point). ## Warning: Removed 33 rows containing missing values (geom_point). # Using {car} border &lt;- car::dataEllipse(cbind(kcoefs$gamma, kcoefs$beta), levels = 0.95) %&gt;% as_tibble() ggplot() + geom_point(aes(x = x, y = y), data = border, col = &quot;red&quot;) + geom_point(aes(x = gamma, y = beta), data = kcoefs, alpha = 0.5) + geom_vline(xintercept = 0) + geom_hline(yintercept = 0) 4.3.1.2 Sampling Matrix Approach An approach, according to Bingham et al 1982, is to use the sampling matrix, generated from the following formulas and calculated below. The key formulas for the population cosinor confidence intervals are: $$ \\begin{aligned} MESOR &amp; \\ A &amp;t_{1 - /2} \\ &amp;+ arctan() \\end{aligned} $$ Where the matrix variables are shown below: $$ \\begin{aligned} s_{22} &amp;= \\ s_{23} &amp;= \\ s_{33} &amp;= \\end{aligned} $$ Thus, we can use these equations to calculate the confidence intervals. # Stats alpha &lt;- 0.05 tdist &lt;- qt(1 - alpha/2, k - 1) # Matrix variables s22 &lt;- ((sb^2 * beta^2) + (2 * sbg * beta * gamma) + (sg^2 * gamma^2)) / (k * amp^2) s23 &lt;- (-1 * (sb^2 - sg^2) * (beta * gamma) + sbg * (beta^2 - gamma^2)) / (k * amp^2) s33 &lt;- ((sb^2 * gamma^2) - (2 * sbg * beta * gamma) + (sg^2 * beta^2)) / (k * amp^2) 4.3.1.3 Approach by Fernandez (Fernández, Mojón, and Hermida 2004) The population aproach can also be predicted through an alternative, perhaps more intuitive way. If normality is assumed, the estimated parameters can be generated from the individual parameters, similar to the MESOR, in a single population, and allows for simple statistical testing between populations. (Fernández, Mojón, and Hermida 2004) # Stats kcoefs &lt;- data.frame(xmat) alpha &lt;- 0.05 tdist &lt;- qt(1 - alpha/2, k - 1) # Plot g &lt;- ggplot() + geom_segment( aes( x = gamma - (tdist * sd(kcoefs$gamma) / sqrt(k)), xend = gamma + (tdist * sd(kcoefs$gamma) / sqrt(k)), y = 0, yend = 0 ), col = &quot;cornflowerblue&quot;, size = 2 ) + geom_segment( aes( y = beta - (tdist * sd(kcoefs$beta) / sqrt(k)), yend = beta + (tdist * sd(kcoefs$beta) / sqrt(k)), x = 0, xend = 0 ), col = &quot;indianred&quot;, size = 2 ) + geom_rect( aes( ymin = beta - (tdist * sd(kcoefs$beta) / sqrt(k)), ymax = beta + (tdist * sd(kcoefs$beta) / sqrt(k)), xmin = 0, xmax = gamma + (tdist * sd(kcoefs$gamma) / sqrt(k)) ), fill = &quot;indianred&quot;, alpha = 0.5 ) + geom_rect( aes( ymin = 0, ymax = beta - (tdist * sd(kcoefs$beta) / sqrt(k)), xmin = gamma - (tdist * sd(kcoefs$gamma) / sqrt(k)), xmax = gamma + (tdist * sd(kcoefs$gamma) / sqrt(k)) ), fill = &quot;cornflowerblue&quot;, alpha = 0.5 ) + geom_point(aes(x = gamma, y = beta), size = 2) + geom_segment( aes( x = 0, y = 0, xend = -amp*sin(phi), yend = amp*cos(phi) ), size = 1.2 ) + geom_vline(xintercept = 0) + geom_hline(yintercept = 0) # Values possible for amplitude is.logical(round(kcoefs$amp * cos(kcoefs$phi), 3) == round(kcoefs$beta, 3)) ## [1] TRUE # Values for phi is.logical(round(kcoefs$amp * -1 * sin(kcoefs$phi), 3) == round(kcoefs$gamma, 3)) ## [1] TRUE sd(kcoefs$beta) ## [1] 0.3023976 sd(kcoefs$gamma) ## [1] 0.2376721 However, this method is more complicated when multiple components are included. References "],
["multiple-component-cosinor.html", "4.4 Multiple-Component Cosinor", " 4.4 Multiple-Component Cosinor Fitting physiological/circadian data may involve other patterns than a single, 24-hour frequency. There may be additional components or cosine waves that better explain the datasets, such as at 8 hours (e.g. meal times). Thus, it can be beneficial to add a secondary component. Implementing this in R is made complex as it now uses a variable number of inputs and variable number of outputs. "],
["package.html", "Chapter 5 Package Development", " Chapter 5 Package Development CRAN supports the publishing of open-source packages in R. The workflow on package development is improved by the following supporting packages: devtools pkgdown usethis testthat roxygen hardhat (creating modeling functions) In addition, git and Github are fundamental for version control in the development process. These resources were used in the development of my first package, card. "],
["documenting-a-package.html", "5.1 Documenting a Package", " 5.1 Documenting a Package The use of roxygen is fundamental in the process of package development, forcing explanatory variables and parameters to be documented as functions are developed. 5.1.1 Website The package pkgdown helps turn documentation into a visually attractive and navigable website. In addition, in the fashion of R, package logos are developed with a hexagon-framed sticker, representing a package. The development of a hex sticker is aided by the use of: https://github.com/GuangchuangYu/hexSticker http://connect.thinkr.fr/hexmake/ "],
["models.html", "Chapter 6 Modeling", " Chapter 6 Modeling Here is a collection of explorations on modeling approaches as they related to electrocardiography and epidemiology. "],
["modeling-multiple-outcomes-and-predictors.html", "6.1 Modeling Multiple Outcomes and Predictors", " 6.1 Modeling Multiple Outcomes and Predictors A recurrent issue with causality-focused modeling with ECG data is that there are multiple outcomes (different ECG features). For example, in the card package, the geh dataset contains several ECG features based on vectorcardiography. 6.1.1 Creating Multiple Models library(card) library(tidyverse) data(geh) names(geh) ## [1] &quot;pid&quot; &quot;hhp_id&quot; &quot;age&quot; ## [4] &quot;sex&quot; &quot;age_cat&quot; &quot;systolic_bp_first&quot; ## [7] &quot;systolic_bp_second&quot; &quot;systolic_bp_third&quot; &quot;diastolic_bp_first&quot; ## [10] &quot;diastolic_bp_second&quot; &quot;diastolic_bp_third&quot; &quot;pulse_rate_first&quot; ## [13] &quot;pulse_rate_second&quot; &quot;height_cm&quot; &quot;weight_kg&quot; ## [16] &quot;waist_cm&quot; &quot;dia_trt_allopdrug&quot; &quot;hbp_trt_allopdrug&quot; ## [19] &quot;hyp_trt_allopdrug&quot; &quot;lab_hba1c&quot; &quot;lab_fasting_bg&quot; ## [22] &quot;lab_fasting_insulin&quot; &quot;lab_tchol&quot; &quot;lab_ldlchol&quot; ## [25] &quot;lab_hdlchol&quot; &quot;lab_triglyc&quot; &quot;lab_ser_urea&quot; ## [28] &quot;lab_ser_creatinine&quot; &quot;lab_urin_malbumin&quot; &quot;pd_heart&quot; ## [31] &quot;bmi&quot; &quot;bmi_cat&quot; &quot;obese&quot; ## [34] &quot;obese_asian&quot; &quot;sbp_mean&quot; &quot;dbp_mean&quot; ## [37] &quot;pulse_mean&quot; &quot;htn&quot; &quot;cad&quot; ## [40] &quot;drugs_dm&quot; &quot;dm&quot; &quot;dm_lab&quot; ## [43] &quot;dm_control&quot; &quot;dm_pre&quot; &quot;homa&quot; ## [46] &quot;high_waist&quot; &quot;high_tchol&quot; &quot;high_ldl&quot; ## [49] &quot;low_hdl&quot; &quot;high_triglyc&quot; &quot;met_syn_num&quot; ## [52] &quot;met_syn&quot; &quot;pr_interval&quot; &quot;p_duration&quot; ## [55] &quot;p_amp&quot; &quot;qrs_duration&quot; &quot;qt_interval&quot; ## [58] &quot;cornell_voltage&quot; &quot;nhanes_score&quot; &quot;svg_mag&quot; ## [61] &quot;az_svg&quot; &quot;az_svg_m&quot; &quot;el_svg&quot; ## [64] &quot;el_svg_m&quot; &quot;qrs_tang&quot; &quot;auc_vm_qt&quot; ## [67] &quot;wvg&quot; &quot;log_svg&quot; &quot;log_auc_qt&quot; ## [70] &quot;log_wvg&quot; The first issue is the causal model, which can be visualized using a directed acyclic graph. The variables of interest are a subset of the dataset. In this case, we’re looking at the relationship of diabetes with cardiotoxicity in a very small subset of participants. library(ggdag) ## ## Attaching package: &#39;ggdag&#39; ## The following object is masked from &#39;package:stats&#39;: ## ## filter bd &lt;- dagify( GEH ~ DM + Age + BMI + HTN + CAD + IR + Sex, DM ~ Age + IR + BMI, CAD ~ DM + BMI + HTN + Age + Sex, HTN ~ Age, IR ~ BMI + Age, Age ~ Sex, exposure = &quot;DM&quot;, outcome = &quot;GEH&quot; ) d1 &lt;- ggdag_parents(bd, &quot;DM&quot;, layout = &quot;star&quot;) + theme_dag() + theme(legend.position = &quot;none&quot;) + labs(title = &quot;Factors Affecting Diabetes&quot;) d2 &lt;- ggdag_parents(bd, &quot;GEH&quot;, layout = &quot;star&quot;) + theme_dag() + theme(legend.position = &quot;none&quot;) + labs(title = &quot;Factors Affecting GEH&quot;) # Combine and plot gridExtra::grid.arrange(d1, d2, nrow = 1) As we can see, many things effect ECG findings, and a subgroup of those impact diabetes, suggesting a number of potential effect modifiers and potential confounders/mediators. Using a sequential model building method in the card package allows for a simple way to perform this analysis. This will build a linear model for each outcome, and repeat the model with an additional covariate in the sequence of listed in the formula. # Select variables vars &lt;- c(&quot;svg_mag&quot;, &quot;az_svg&quot;, &quot;el_svg&quot;, &quot;qrs_tang&quot;, &quot;log_auc_qt&quot;, &quot;log_wvg&quot;, &quot;lab_hba1c&quot;, &quot;lab_fasting_bg&quot;, &quot;homa&quot;, &quot;dm&quot;, &quot;age&quot;, &quot;bmi&quot;, &quot;bmi_cat&quot;, &quot;age_cat&quot;, &quot;sex&quot;, &quot;htn&quot;, &quot;cad&quot;, &quot;lab_ser_creatinine&quot;, &quot;lab_tchol&quot;) df &lt;- geh %&gt;% select(all_of(vars)) %&gt;% #na.omit() %&gt;% #filter(homa &lt;= 5 * sd(homa, na.rm = TRUE)) %&gt;% # Remove outliers mutate( bmi_cat = factor(bmi_cat, levels = c(0:3), labels = c(&quot;Underweight&quot;, &quot;Normal&quot;, &quot;Overweight&quot;, &quot;Obese&quot;)), age_cat = factor(age_cat, levels = c(0:2), labels = c(&quot;&lt;45&quot;, &quot;45-65&quot;, &quot;&gt;65&quot;)), sex = factor(sex, levels = c(0,1), labels = c(&quot;Female&quot;, &quot;Male&quot;)) ) %&gt;% mutate(across( c(svg_mag, az_svg, el_svg, qrs_tang, log_auc_qt, log_wvg), function(x) { as.vector(scale(x, center = TRUE, scale = TRUE)) } )) # Sequential model building models &lt;- card::build_sequential_models( svg_mag + az_svg + el_svg + qrs_tang + log_auc_qt + log_wvg ~ lab_hba1c + age + sex + bmi + cad + htn, data = df, exposure = &quot;lab_hba1c&quot;, engine = &quot;lm&quot; ) head(models) ## # A tibble: 6 x 7 ## outcomes term estimate std.error statistic p.value covar ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 svg_mag (Intercept) 0.339 0.196 1.73 0.0847 1 ## 2 svg_mag lab_hba1c -0.0412 0.0234 -1.76 0.0796 1 ## 3 az_svg (Intercept) -0.315 0.195 -1.62 0.107 1 ## 4 az_svg lab_hba1c 0.0381 0.0233 1.64 0.102 1 ## 5 el_svg (Intercept) 0.0767 0.195 0.394 0.694 1 ## 6 el_svg lab_hba1c -0.00862 0.0233 -0.370 0.711 1 6.1.2 Visualize Regression Estimates To assess or get a sense of how the variables are playing out, we can visualize the estimates across the builds of the models. This will also use the gganimate package to show the effect of data layering # Libraries library(gganimate) library(ggthemes) # Data df &lt;- models %&gt;% # Remove intercepts filter(term != &quot;(Intercept)&quot;) %&gt;% # Sequence the terms mutate( term = factor( term, levels = c(&quot;lab_hba1c&quot;, &quot;age&quot;, &quot;sexMale&quot;, &quot;bmi&quot;, &quot;cad1&quot;, &quot;htn1&quot;), labels = c(&quot;HbA1c&quot;, &quot;Age&quot;, &quot;Sex&quot;, &quot;BMI&quot;, &quot;CAD&quot;, &quot;HTN&quot;) ) ) # ggplot g &lt;- ggplot(df, aes(x = factor(covar), y = estimate, color = term)) + facet_wrap(~outcomes, scales = &quot;fixed&quot;) + geom_point( aes(color = term), data = filter(df, p.value &gt;= 0.20), shape = 1, position = &quot;jitter&quot; ) + geom_point( aes(color = term), data = filter(df, p.value &lt; 0.20), shape = 19, position = &quot;jitter&quot; ) + scale_color_ptol(name = &quot;Predictors&quot;) + theme_minimal() + theme( legend.position = &quot;bottom&quot;, legend.box = &quot;horizontal&quot;, panel.border = element_rect(colour = &quot;black&quot;, fill = NA) ) + labs( title = &quot;Estimates in Sequential Models&quot;, x = &quot;Number of Covariates in Model&quot;, y = &quot;GEH Parameters (z-normalized)&quot; ) # Animated a &lt;- g + transition_reveal(covar) animate(a, width = 700, height = 400, end_pause = 30) "],
["vcg.html", "Chapter 7 Vectorcardiography ", " Chapter 7 Vectorcardiography "],
["vector-gradients.html", "7.1 Vector Gradients", " 7.1 Vector Gradients Mark Josephson in 1988 found that repolarization became non-uniform post-infarction, which was the suggestive substrate of VT/VF. The dispersion of the total recovery time is suggestive of global electrical heterogeneity, which can then predict SCD. Vectorcardiography (VCG) characterizes the electrical heart vector movement through a cardiac cycle. This is understood best through the spatial ventricular gradient vector (SVG), as described by Frank Wilson in 1934, and expanded upon by J. Willis Hurst. This is different and independent of the sequence of ventricular activation, which can be seen on ECG. The work by Larisa Tereschchenko has helped to compute these concepts for analytical approaches (Tereshchenko 2018). The SVG points to different locations in healthy versus diseased hearts. Summary of SVG: Points along the direction of greatest activation and recovery time (which is perpendicular to the line of conduction block, such as scar) Points towards to the area where the total recovery time is the shortest Depends on the heterogeneity of action potential across entire myocardium Characterizes the degree of heterogeneity of recovery time across the ventricles Steepness of the gradient determines magnitude of the SVG (areas of contrasting recovery time thus give largest SVG) References "],
["global-electrical-heterogeneity.html", "7.2 Global Electrical Heterogeneity", " 7.2 Global Electrical Heterogeneity The SVG can be broken down in 5 VCG parameters to describe the overall global electrical heterogeneity of the heart, as seen in the Figure below (Waks et al. 2016). SVG magnitude SVG azimuth SVG elevation Spatial QRS-T angle = the three-dimensional angle between mean spatial QRS-vector and mean spatial T-vector, measured in degrees Sum absolute QRST integral = scalar analog of the SVG, calculated as absolute value under QRS cmplex and T-wave, measured in millivolts (integral of voltage over time) vector gradient "]
]
